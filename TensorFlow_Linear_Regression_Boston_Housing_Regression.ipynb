{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c9418c",
   "metadata": {},
   "source": [
    "# Importing of Key libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "2ab0851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9fc6e2",
   "metadata": {},
   "source": [
    "# Calling of the function to pull the data split into x_train_x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "f3a20d91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "    path='boston_housing.npz', test_split=0.2, seed=113\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5db6df",
   "metadata": {},
   "source": [
    "# Function to get the split of data - x_train_x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "f56c69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.src.api_export import keras_export\n",
    "from keras.src.utils.file_utils import get_file\n",
    "\n",
    "\n",
    "@keras_export(\"keras.datasets.boston_housing.load_data\")\n",
    "def load_data(path=\"boston_housing.npz\", test_split=0.2, seed=113):\n",
    "    \"\"\"Loads the Boston Housing dataset.\n",
    "\n",
    "    This is a dataset taken from the StatLib library which is maintained at\n",
    "    Carnegie Mellon University.\n",
    "\n",
    "    **WARNING:** This dataset has an ethical problem: the authors of this\n",
    "    dataset included a variable, \"B\", that may appear to assume that racial\n",
    "    self-segregation influences house prices. As such, we strongly discourage\n",
    "    the use of this dataset, unless in the context of illustrating ethical\n",
    "    issues in data science and machine learning.\n",
    "\n",
    "    Samples contain 13 attributes of houses at different locations around the\n",
    "    Boston suburbs in the late 1970s. Targets are the median values of\n",
    "    the houses at a location (in k$).\n",
    "\n",
    "    The attributes themselves are defined in the\n",
    "    [StatLib website](http://lib.stat.cmu.edu/datasets/boston).\n",
    "\n",
    "    Args:\n",
    "        path: path where to cache the dataset locally\n",
    "            (relative to `~/.keras/datasets`).\n",
    "        test_split: fraction of the data to reserve as test set.\n",
    "        seed: Random seed for shuffling the data\n",
    "            before computing the test split.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of NumPy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "\n",
    "    **x_train, x_test**: NumPy arrays with shape `(num_samples, 13)`\n",
    "        containing either the training samples (for x_train),\n",
    "        or test samples (for y_train).\n",
    "\n",
    "    **y_train, y_test**: NumPy arrays of shape `(num_samples,)` containing the\n",
    "        target scalars. The targets are float scalars typically between 10 and\n",
    "        50 that represent the home prices in k$.\n",
    "    \"\"\"\n",
    "    assert 0 <= test_split < 1\n",
    "    origin_folder = (\n",
    "        \"https://storage.googleapis.com/tensorflow/tf-keras-datasets/\"\n",
    "    )\n",
    "    path = get_file(\n",
    "        path,\n",
    "        origin=origin_folder + \"boston_housing.npz\",\n",
    "        file_hash=(  # noqa: E501\n",
    "            \"f553886a1f8d56431e820c5b82552d9d95cfcb96d1e678153f8839538947dff5\"\n",
    "        ),\n",
    "    )\n",
    "    with np.load(path, allow_pickle=True) as f:\n",
    "        x = f[\"x\"]\n",
    "        y = f[\"y\"]\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    indices = np.arange(len(x))\n",
    "    rng.shuffle(indices)\n",
    "    x = x[indices]\n",
    "    y = y[indices]\n",
    "\n",
    "    x_train = np.array(x[: int(len(x) * (1 - test_split))])\n",
    "    y_train = np.array(y[: int(len(x) * (1 - test_split))])\n",
    "    x_test = np.array(x[int(len(x) * (1 - test_split)) :])\n",
    "    y_test = np.array(y[int(len(x) * (1 - test_split)) :])\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d56258c",
   "metadata": {},
   "source": [
    "# displaying of the data set (x_train,y_train) &  (x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "3fe67aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[1.23247e+00, 0.00000e+00, 8.14000e+00, ..., 2.10000e+01,\n",
       "          3.96900e+02, 1.87200e+01],\n",
       "         [2.17700e-02, 8.25000e+01, 2.03000e+00, ..., 1.47000e+01,\n",
       "          3.95380e+02, 3.11000e+00],\n",
       "         [4.89822e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "          3.75520e+02, 3.26000e+00],\n",
       "         ...,\n",
       "         [3.46600e-02, 3.50000e+01, 6.06000e+00, ..., 1.69000e+01,\n",
       "          3.62250e+02, 7.83000e+00],\n",
       "         [2.14918e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "          2.61950e+02, 1.57900e+01],\n",
       "         [1.43900e-02, 6.00000e+01, 2.93000e+00, ..., 1.56000e+01,\n",
       "          3.76700e+02, 4.38000e+00]]),\n",
       "  array([15.2, 42.3, 50. , 21.1, 17.7, 18.5, 11.3, 15.6, 15.6, 14.4, 12.1,\n",
       "         17.9, 23.1, 19.9, 15.7,  8.8, 50. , 22.5, 24.1, 27.5, 10.9, 30.8,\n",
       "         32.9, 24. , 18.5, 13.3, 22.9, 34.7, 16.6, 17.5, 22.3, 16.1, 14.9,\n",
       "         23.1, 34.9, 25. , 13.9, 13.1, 20.4, 20. , 15.2, 24.7, 22.2, 16.7,\n",
       "         12.7, 15.6, 18.4, 21. , 30.1, 15.1, 18.7,  9.6, 31.5, 24.8, 19.1,\n",
       "         22. , 14.5, 11. , 32. , 29.4, 20.3, 24.4, 14.6, 19.5, 14.1, 14.3,\n",
       "         15.6, 10.5,  6.3, 19.3, 19.3, 13.4, 36.4, 17.8, 13.5, 16.5,  8.3,\n",
       "         14.3, 16. , 13.4, 28.6, 43.5, 20.2, 22. , 23. , 20.7, 12.5, 48.5,\n",
       "         14.6, 13.4, 23.7, 50. , 21.7, 39.8, 38.7, 22.2, 34.9, 22.5, 31.1,\n",
       "         28.7, 46. , 41.7, 21. , 26.6, 15. , 24.4, 13.3, 21.2, 11.7, 21.7,\n",
       "         19.4, 50. , 22.8, 19.7, 24.7, 36.2, 14.2, 18.9, 18.3, 20.6, 24.6,\n",
       "         18.2,  8.7, 44. , 10.4, 13.2, 21.2, 37. , 30.7, 22.9, 20. , 19.3,\n",
       "         31.7, 32. , 23.1, 18.8, 10.9, 50. , 19.6,  5. , 14.4, 19.8, 13.8,\n",
       "         19.6, 23.9, 24.5, 25. , 19.9, 17.2, 24.6, 13.5, 26.6, 21.4, 11.9,\n",
       "         22.6, 19.6,  8.5, 23.7, 23.1, 22.4, 20.5, 23.6, 18.4, 35.2, 23.1,\n",
       "         27.9, 20.6, 23.7, 28. , 13.6, 27.1, 23.6, 20.6, 18.2, 21.7, 17.1,\n",
       "          8.4, 25.3, 13.8, 22.2, 18.4, 20.7, 31.6, 30.5, 20.3,  8.8, 19.2,\n",
       "         19.4, 23.1, 23. , 14.8, 48.8, 22.6, 33.4, 21.1, 13.6, 32.2, 13.1,\n",
       "         23.4, 18.9, 23.9, 11.8, 23.3, 22.8, 19.6, 16.7, 13.4, 22.2, 20.4,\n",
       "         21.8, 26.4, 14.9, 24.1, 23.8, 12.3, 29.1, 21. , 19.5, 23.3, 23.8,\n",
       "         17.8, 11.5, 21.7, 19.9, 25. , 33.4, 28.5, 21.4, 24.3, 27.5, 33.1,\n",
       "         16.2, 23.3, 48.3, 22.9, 22.8, 13.1, 12.7, 22.6, 15. , 15.3, 10.5,\n",
       "         24. , 18.5, 21.7, 19.5, 33.2, 23.2,  5. , 19.1, 12.7, 22.3, 10.2,\n",
       "         13.9, 16.3, 17. , 20.1, 29.9, 17.2, 37.3, 45.4, 17.8, 23.2, 29. ,\n",
       "         22. , 18. , 17.4, 34.6, 20.1, 25. , 15.6, 24.8, 28.2, 21.2, 21.4,\n",
       "         23.8, 31. , 26.2, 17.4, 37.9, 17.5, 20. ,  8.3, 23.9,  8.4, 13.8,\n",
       "          7.2, 11.7, 17.1, 21.6, 50. , 16.1, 20.4, 20.6, 21.4, 20.6, 36.5,\n",
       "          8.5, 24.8, 10.8, 21.9, 17.3, 18.9, 36.2, 14.9, 18.2, 33.3, 21.8,\n",
       "         19.7, 31.6, 24.8, 19.4, 22.8,  7.5, 44.8, 16.8, 18.7, 50. , 50. ,\n",
       "         19.5, 20.1, 50. , 17.2, 20.8, 19.3, 41.3, 20.4, 20.5, 13.8, 16.5,\n",
       "         23.9, 20.6, 31.5, 23.3, 16.8, 14. , 33.8, 36.1, 12.8, 18.3, 18.7,\n",
       "         19.1, 29. , 30.1, 50. , 50. , 22. , 11.9, 37.6, 50. , 22.7, 20.8,\n",
       "         23.5, 27.9, 50. , 19.3, 23.9, 22.6, 15.2, 21.7, 19.2, 43.8, 20.3,\n",
       "         33.2, 19.9, 22.5, 32.7, 22. , 17.1, 19. , 15. , 16.1, 25.1, 23.7,\n",
       "         28.7, 37.2, 22.6, 16.4, 25. , 29.8, 22.1, 17.4, 18.1, 30.3, 17.5,\n",
       "         24.7, 12.6, 26.5, 28.7, 13.3, 10.4, 24.4, 23. , 20. , 17.8,  7. ,\n",
       "         11.8, 24.4, 13.8, 19.4, 25.2, 19.4, 19.4, 29.1])),\n",
       " (array([[1.80846e+01, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "          2.72500e+01, 2.90500e+01],\n",
       "         [1.23290e-01, 0.00000e+00, 1.00100e+01, ..., 1.78000e+01,\n",
       "          3.94950e+02, 1.62100e+01],\n",
       "         [5.49700e-02, 0.00000e+00, 5.19000e+00, ..., 2.02000e+01,\n",
       "          3.96900e+02, 9.74000e+00],\n",
       "         ...,\n",
       "         [1.83377e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "          3.89610e+02, 1.92000e+00],\n",
       "         [3.58090e-01, 0.00000e+00, 6.20000e+00, ..., 1.74000e+01,\n",
       "          3.91700e+02, 9.71000e+00],\n",
       "         [2.92400e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "          2.40160e+02, 9.81000e+00]]),\n",
       "  array([ 7.2, 18.8, 19. , 27. , 22.2, 24.5, 31.2, 22.9, 20.5, 23.2, 18.6,\n",
       "         14.5, 17.8, 50. , 20.8, 24.3, 24.2, 19.8, 19.1, 22.7, 12. , 10.2,\n",
       "         20. , 18.5, 20.9, 23. , 27.5, 30.1,  9.5, 22. , 21.2, 14.1, 33.1,\n",
       "         23.4, 20.1,  7.4, 15.4, 23.8, 20.1, 24.5, 33. , 28.4, 14.1, 46.7,\n",
       "         32.5, 29.6, 28.4, 19.8, 20.2, 25. , 35.4, 20.3,  9.7, 14.5, 34.9,\n",
       "         26.6,  7.2, 50. , 32.4, 21.6, 29.8, 13.1, 27.5, 21.2, 23.1, 21.9,\n",
       "         13. , 23.2,  8.1,  5.6, 21.7, 29.6, 19.6,  7. , 26.4, 18.9, 20.9,\n",
       "         28.1, 35.4, 10.2, 24.3, 43.1, 17.6, 15.4, 16.2, 27.1, 21.4, 21.5,\n",
       "         22.4, 25. , 16.6, 18.6, 22. , 42.8, 35.1, 21.5, 36. , 21.9, 24.1,\n",
       "         50. , 26.7, 25. ])))"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea9b34e",
   "metadata": {},
   "source": [
    "# checking on the length and shape of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "cee90b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 102, 404, 102)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train),len(x_test),len(y_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "441c0552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((404, 13), (404,))"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape , y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e48b2",
   "metadata": {},
   "source": [
    "# Model on the training data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894aa466",
   "metadata": {},
   "source": [
    "# MODEL 1 : Model with 1 input and 1 output layer, optimizer as Adam and epochs = 10\n",
    "\n",
    "OUTPUT HAS HIGH LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "55ae798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 48.0384 - mae: 48.0384\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41.3597 - mae: 41.3597 \n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35.5526 - mae: 35.5526 \n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.8533 - mae: 30.8533 \n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27.4918 - mae: 27.4918 \n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.3474 - mae: 25.3474 \n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.9453 - mae: 23.9453 \n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.0067 - mae: 23.0067 \n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.1950 - mae: 22.1950 \n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.4484 - mae: 21.4484 \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "boston_housing_model_1 = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(1,activation = None),\n",
    "     tf.keras.layers.Dense(1,activation = None)\n",
    "])\n",
    "\n",
    "\n",
    "boston_housing_model_1.compile(loss = tf.keras.losses.mae,\n",
    "                               optimizer = tf.keras.optimizers.Adam(),\n",
    "                               metrics = [\"mae\"])\n",
    "\n",
    "history_1 = boston_housing_model_1.fit(x_train,y_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fe6233",
   "metadata": {},
   "source": [
    "# MODEL 2 : Model with 2 input and 1 output layer, optimizer as Adam and epochs = 10\n",
    "\n",
    "OUTPUT LOSS HAS DECREASED BUT HAS SCOPE OF FURTHER REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "ffe5d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 81.8410 - mae: 81.8410  \n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 15.5295 - mae: 15.5295 \n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - loss: 11.5258 - mae: 11.5258\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 10.2488 - mae: 10.2488 \n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9133 - mae: 9.9133 \n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2789 - mae: 9.2789   \n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9356 - mae: 8.9356 \n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.6470 - mae: 8.6470 \n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4245 - mae: 8.4245 \n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.1217 - mae: 8.1217 \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "boston_housing_model_2 = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(10,activation = None),\n",
    "     tf.keras.layers.Dense(10,activation = None),\n",
    "     tf.keras.layers.Dense(1,activation = None)\n",
    "])\n",
    "\n",
    "\n",
    "boston_housing_model_2.compile(loss = tf.keras.losses.mae,\n",
    "                               optimizer = tf.keras.optimizers.Adam(),\n",
    "                               metrics = [\"mae\"])\n",
    "\n",
    "history_2 = boston_housing_model_2.fit(x_train,y_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6184650c",
   "metadata": {},
   "source": [
    "# MODEL 3 : Model with 3 input and 1 output layer, optimizer as Adam and epochs = 10\n",
    "\n",
    "OUTPUT LOSS HAS DECREASED BUT STILL HAS SCOPE OF FURTHER REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "3ec3f600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 134.7318 - mae: 134.7318\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.1746 - mae: 28.1746 \n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 23.2878 - mae: 23.2878 \n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.6088 - mae: 14.6088 \n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.8502 - mae: 9.8502   \n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9.6319 - mae: 9.6319 \n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.3039 - mae: 7.3039 \n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8358 - mae: 6.8358 \n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8056 - mae: 6.8056 \n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8308 - mae: 6.8308 \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "boston_housing_model_3 = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(100,activation = None),\n",
    "     tf.keras.layers.Dense(10,activation = None),\n",
    "     tf.keras.layers.Dense(10,activation = None),\n",
    "     tf.keras.layers.Dense(1,activation = None)\n",
    "])\n",
    "\n",
    "\n",
    "boston_housing_model_3.compile(loss = tf.keras.losses.mae,\n",
    "                               optimizer = tf.keras.optimizers.Adam(),\n",
    "                               metrics = [\"mae\"])\n",
    "\n",
    "history_3 = boston_housing_model_3.fit(x_train,y_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ace0cf6",
   "metadata": {},
   "source": [
    "# MODEL 4 : Model with 3 input and 1 output layer, optimizer as Adam and epochs = 10 and Adam learning rate = 0.1\n",
    "\n",
    "OUTPUT LOSS HAS DECREASED BUT STILL HAS SCOPE OF FURTHER REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "95505987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 860.6168 - mae: 860.6168\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 102.7777 - mae: 102.7777 \n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 31.0613 - mae: 31.0613 \n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 14.9345 - mae: 14.9345 \n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.8302 - mae: 6.8302 \n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.0938 - mae: 6.0938 \n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.3193 - mae: 6.3193 \n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9054 - mae: 5.9054 \n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 587us/step - loss: 5.7213 - mae: 5.7213\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.7452 - mae: 5.7452 \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "boston_housing_model_4 = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(100,activation = None),\n",
    "     tf.keras.layers.Dense(10,activation = None),\n",
    "     tf.keras.layers.Dense(10,activation = None),\n",
    "     tf.keras.layers.Dense(1,activation = None)\n",
    "])\n",
    "\n",
    "\n",
    "boston_housing_model_4.compile(loss = tf.keras.losses.mae,\n",
    "                               optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1),\n",
    "                               metrics = [\"mae\"])\n",
    "\n",
    "history_4 = boston_housing_model_4.fit(x_train,y_train,epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba69c9c0",
   "metadata": {},
   "source": [
    "# MODEL 5 : Model with 3 input and 1 output layer, optimizer as Adam and epochs = 100 and Adam learning rate = 0.1\n",
    "\n",
    "OYTPUT LOSS HAS REDUCED BUT STILL HAS SCOPE OF FURTHER REDUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "5e5accfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 1122.5753 - mae: 1122.5753\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 114.0749 - mae: 114.0749 \n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.7275 - mae: 21.7275 \n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.3852 - mae: 11.3852 \n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.8064 - mae: 7.8064   \n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.2790 - mae: 6.2790 \n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1611 - mae: 6.1611 \n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.2070 - mae: 6.2070 \n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9870 - mae: 5.9870 \n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.9394 - mae: 5.9394 \n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step - loss: 5.8003 - mae: 5.8003\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.8238 - mae: 5.8238 \n",
      "Epoch 13/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7032 - mae: 5.7032 \n",
      "Epoch 14/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6207 - mae: 5.6207 \n",
      "Epoch 15/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5402 - mae: 5.5402 \n",
      "Epoch 16/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5267 - mae: 5.5267 \n",
      "Epoch 17/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5544 - mae: 5.5544 \n",
      "Epoch 18/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.6233 - mae: 5.6233 \n",
      "Epoch 19/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1703 - mae: 5.1703 \n",
      "Epoch 20/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8895 - mae: 4.8895 \n",
      "Epoch 21/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6571 - mae: 4.6571 \n",
      "Epoch 22/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2283 - mae: 5.2283 \n",
      "Epoch 23/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0300 - mae: 5.0300 \n",
      "Epoch 24/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8932 - mae: 4.8932 \n",
      "Epoch 25/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7299 - mae: 4.7299 \n",
      "Epoch 26/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6028 - mae: 4.6028 \n",
      "Epoch 27/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.1627 - mae: 5.1627 \n",
      "Epoch 28/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4506 - mae: 5.4506 \n",
      "Epoch 29/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.7644 - mae: 5.7644 \n",
      "Epoch 30/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.4902 - mae: 5.4902 \n",
      "Epoch 31/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9367 - mae: 4.9367 \n",
      "Epoch 32/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7184 - mae: 4.7184 \n",
      "Epoch 33/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5332 - mae: 4.5332 \n",
      "Epoch 34/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5715 - mae: 4.5715 \n",
      "Epoch 35/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.8154 - mae: 4.8154 \n",
      "Epoch 36/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5077 - mae: 4.5077 \n",
      "Epoch 37/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3579 - mae: 4.3579 \n",
      "Epoch 38/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2588 - mae: 4.2588 \n",
      "Epoch 39/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4674 - mae: 4.4674 \n",
      "Epoch 40/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3080 - mae: 4.3080 \n",
      "Epoch 41/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5680 - mae: 4.5680 \n",
      "Epoch 42/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3874 - mae: 4.3874 \n",
      "Epoch 43/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2382 - mae: 4.2382 \n",
      "Epoch 44/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3402 - mae: 4.3402 \n",
      "Epoch 45/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.4263 - mae: 4.4263 \n",
      "Epoch 46/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7059 - mae: 4.7059 \n",
      "Epoch 47/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4028 - mae: 4.4028 \n",
      "Epoch 48/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2400 - mae: 4.2400 \n",
      "Epoch 49/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5122 - mae: 4.5122 \n",
      "Epoch 50/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4498 - mae: 4.4498 \n",
      "Epoch 51/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0759 - mae: 4.0759 \n",
      "Epoch 52/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3523 - mae: 4.3523 \n",
      "Epoch 53/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0636 - mae: 4.0636 \n",
      "Epoch 54/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4565 - mae: 4.4565 \n",
      "Epoch 55/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1688 - mae: 4.1688\n",
      "Epoch 56/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2824 - mae: 4.2824 \n",
      "Epoch 57/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2648 - mae: 4.2648 \n",
      "Epoch 58/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2044 - mae: 4.2044 \n",
      "Epoch 59/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4636 - mae: 4.4636 \n",
      "Epoch 60/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0121 - mae: 4.0121 \n",
      "Epoch 61/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1847 - mae: 4.1847 \n",
      "Epoch 62/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9821 - mae: 3.9821 \n",
      "Epoch 63/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2616 - mae: 4.2616 \n",
      "Epoch 64/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - loss: 4.2806 - mae: 4.2806\n",
      "Epoch 65/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3601 - mae: 4.3601 \n",
      "Epoch 66/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3768 - mae: 4.3768 \n",
      "Epoch 67/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1713 - mae: 4.1713 \n",
      "Epoch 68/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 4.1066 - mae: 4.1066\n",
      "Epoch 69/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3451 - mae: 4.3451 \n",
      "Epoch 70/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1558 - mae: 4.1558 \n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1794 - mae: 4.1794 \n",
      "Epoch 72/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9854 - mae: 3.9854 \n",
      "Epoch 73/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - loss: 3.9305 - mae: 3.9305\n",
      "Epoch 74/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0882 - mae: 4.0882 \n",
      "Epoch 75/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9689 - mae: 3.9689 \n",
      "Epoch 76/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7355 - mae: 3.7355 \n",
      "Epoch 77/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0639 - mae: 4.0639 \n",
      "Epoch 78/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7913 - mae: 3.7913 \n",
      "Epoch 79/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8760 - mae: 3.8760 \n",
      "Epoch 80/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9206 - mae: 3.9206 \n",
      "Epoch 81/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9073 - mae: 3.9073 \n",
      "Epoch 82/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0233 - mae: 4.0233 \n",
      "Epoch 83/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9751 - mae: 3.9751 \n",
      "Epoch 84/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9487 - mae: 3.9487 \n",
      "Epoch 85/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2336 - mae: 4.2336 \n",
      "Epoch 86/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4543 - mae: 4.4543 \n",
      "Epoch 87/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8255 - mae: 3.8255 \n",
      "Epoch 88/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.1293 - mae: 5.1293 \n",
      "Epoch 89/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4285 - mae: 4.4285 \n",
      "Epoch 90/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0438 - mae: 4.0438 \n",
      "Epoch 91/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1341 - mae: 4.1341 \n",
      "Epoch 92/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0988 - mae: 4.0988 \n",
      "Epoch 93/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8501 - mae: 3.8501 \n",
      "Epoch 94/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8320 - mae: 3.8320 \n",
      "Epoch 95/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0569 - mae: 4.0569 \n",
      "Epoch 96/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9856 - mae: 3.9856 \n",
      "Epoch 97/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9100 - mae: 3.9100 \n",
      "Epoch 98/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8133 - mae: 3.8133 \n",
      "Epoch 99/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1192 - mae: 4.1192 \n",
      "Epoch 100/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9246 - mae: 4.9246 \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "boston_housing_model_5 = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(100,activation = None),\n",
    "     tf.keras.layers.Dense(10,activation = None),\n",
    "     tf.keras.layers.Dense(10,activation = None),\n",
    "     tf.keras.layers.Dense(1,activation = None)\n",
    "])\n",
    "\n",
    "\n",
    "boston_housing_model_5.compile(loss = tf.keras.losses.mae,\n",
    "                               optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1),\n",
    "                               metrics = [\"mae\"])\n",
    "\n",
    "history_5 = boston_housing_model_5.fit(x_train,y_train,epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed63bd4",
   "metadata": {},
   "source": [
    "# MODEL 6 : Model with 3 input and 1 output layer, optimizer as Adam and epochs = 200 and Adam learning rate = 0.1\n",
    "\n",
    "MINOR DROP IN LOSS , NOW IT SEEMS THE FINAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "a06567c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 982.2733 - mae: 982.2733\n",
      "Epoch 2/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 243.9357 - mae: 243.9357 \n",
      "Epoch 3/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 50.1236 - mae: 50.1236 \n",
      "Epoch 4/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 11.9636 - mae: 11.9636 \n",
      "Epoch 5/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8.4306 - mae: 8.4306   \n",
      "Epoch 6/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7.0742 - mae: 7.0742 \n",
      "Epoch 7/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.9254 - mae: 6.9254 \n",
      "Epoch 8/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.6018 - mae: 6.6018 \n",
      "Epoch 9/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 6.5073 - mae: 6.5073 \n",
      "Epoch 10/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1927 - mae: 6.1927 \n",
      "Epoch 11/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0287 - mae: 6.0287 \n",
      "Epoch 12/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5441 - mae: 5.5441 \n",
      "Epoch 13/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.8501 - mae: 5.8501 \n",
      "Epoch 14/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.0482 - mae: 6.0482 \n",
      "Epoch 15/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.9235 - mae: 5.9235 \n",
      "Epoch 16/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.3717 - mae: 5.3717 \n",
      "Epoch 17/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.5882 - mae: 5.5882 \n",
      "Epoch 18/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.1291 - mae: 5.1291 \n",
      "Epoch 19/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6.1927 - mae: 6.1927 \n",
      "Epoch 20/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.2752 - mae: 5.2752 \n",
      "Epoch 21/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0810 - mae: 5.0810 \n",
      "Epoch 22/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.1398 - mae: 5.1398 \n",
      "Epoch 23/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0268 - mae: 5.0268 \n",
      "Epoch 24/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8076 - mae: 4.8076 \n",
      "Epoch 25/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8559 - mae: 4.8559 \n",
      "Epoch 26/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9738 - mae: 4.9738 \n",
      "Epoch 27/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.9345 - mae: 4.9345 \n",
      "Epoch 28/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7369 - mae: 4.7369 \n",
      "Epoch 29/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.2312 - mae: 5.2312 \n",
      "Epoch 30/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0959 - mae: 5.0959 \n",
      "Epoch 31/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7402 - mae: 4.7402 \n",
      "Epoch 32/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7915 - mae: 4.7915 \n",
      "Epoch 33/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5988 - mae: 4.5988 \n",
      "Epoch 34/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.9535 - mae: 4.9535 \n",
      "Epoch 35/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6403 - mae: 4.6403 \n",
      "Epoch 36/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5064 - mae: 4.5064 \n",
      "Epoch 37/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6978 - mae: 4.6978 \n",
      "Epoch 38/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6343 - mae: 4.6343 \n",
      "Epoch 39/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2886 - mae: 4.2886 \n",
      "Epoch 40/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.7127 - mae: 4.7127 \n",
      "Epoch 41/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3117 - mae: 4.3117 \n",
      "Epoch 42/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6083 - mae: 4.6083 \n",
      "Epoch 43/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4058 - mae: 4.4058 \n",
      "Epoch 44/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4529 - mae: 4.4529 \n",
      "Epoch 45/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0303 - mae: 5.0303 \n",
      "Epoch 46/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.6388 - mae: 4.6388 \n",
      "Epoch 47/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3232 - mae: 4.3232 \n",
      "Epoch 48/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4865 - mae: 4.4865 \n",
      "Epoch 49/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4922 - mae: 4.4922 \n",
      "Epoch 50/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1930 - mae: 4.1930 \n",
      "Epoch 51/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8677 - mae: 4.8677 \n",
      "Epoch 52/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0558 - mae: 4.0558 \n",
      "Epoch 53/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4247 - mae: 4.4247 \n",
      "Epoch 54/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0983 - mae: 4.0983 \n",
      "Epoch 55/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6435 - mae: 4.6435 \n",
      "Epoch 56/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0945 - mae: 4.0945 \n",
      "Epoch 57/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2320 - mae: 4.2320 \n",
      "Epoch 58/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2786 - mae: 4.2786 \n",
      "Epoch 59/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2332 - mae: 4.2332 \n",
      "Epoch 60/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3830 - mae: 4.3830 \n",
      "Epoch 61/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4819 - mae: 4.4819 \n",
      "Epoch 62/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.5956 - mae: 4.5956 \n",
      "Epoch 63/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4104 - mae: 4.4104 \n",
      "Epoch 64/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1025 - mae: 4.1025 \n",
      "Epoch 65/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2591 - mae: 4.2591 \n",
      "Epoch 66/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9104 - mae: 3.9104 \n",
      "Epoch 67/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2247 - mae: 4.2247 \n",
      "Epoch 68/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0395 - mae: 4.0395 \n",
      "Epoch 69/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1276 - mae: 4.1276 \n",
      "Epoch 70/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9163 - mae: 3.9163 \n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3107 - mae: 4.3107 \n",
      "Epoch 72/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0256 - mae: 4.0256 \n",
      "Epoch 73/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2009 - mae: 4.2009 \n",
      "Epoch 74/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1313 - mae: 4.1313 \n",
      "Epoch 75/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1914 - mae: 4.1914 \n",
      "Epoch 76/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8607 - mae: 3.8607 \n",
      "Epoch 77/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8622 - mae: 3.8622 \n",
      "Epoch 78/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0571 - mae: 4.0571 \n",
      "Epoch 79/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8058 - mae: 3.8058 \n",
      "Epoch 80/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2217 - mae: 4.2217 \n",
      "Epoch 81/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4987 - mae: 4.4987 \n",
      "Epoch 82/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7750 - mae: 3.7750 \n",
      "Epoch 83/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2993 - mae: 4.2993 \n",
      "Epoch 84/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0566 - mae: 4.0566 \n",
      "Epoch 85/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0380 - mae: 4.0380 \n",
      "Epoch 86/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7661 - mae: 3.7661 \n",
      "Epoch 87/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4242 - mae: 4.4242 \n",
      "Epoch 88/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9932 - mae: 3.9932 \n",
      "Epoch 89/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5041 - mae: 4.5041 \n",
      "Epoch 90/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2842 - mae: 4.2842 \n",
      "Epoch 91/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0717 - mae: 4.0717 \n",
      "Epoch 92/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9801 - mae: 3.9801 \n",
      "Epoch 93/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9262 - mae: 3.9262 \n",
      "Epoch 94/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0761 - mae: 4.0761 \n",
      "Epoch 95/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0333 - mae: 4.0333 \n",
      "Epoch 96/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9628 - mae: 3.9628 \n",
      "Epoch 97/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9901 - mae: 3.9901 \n",
      "Epoch 98/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4866 - mae: 4.4866 \n",
      "Epoch 99/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8663 - mae: 4.8663 \n",
      "Epoch 100/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5.0578 - mae: 5.0578 \n",
      "Epoch 101/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - loss: 3.9881 - mae: 3.9881\n",
      "Epoch 102/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0920 - mae: 4.0920 \n",
      "Epoch 103/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9885 - mae: 3.9885 \n",
      "Epoch 104/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6556 - mae: 3.6556 \n",
      "Epoch 105/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8525 - mae: 3.8525 \n",
      "Epoch 106/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5988 - mae: 3.5988 \n",
      "Epoch 107/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8365 - mae: 3.8365 \n",
      "Epoch 108/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7176 - mae: 3.7176 \n",
      "Epoch 109/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8731 - mae: 3.8731 \n",
      "Epoch 110/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7875 - mae: 3.7875 \n",
      "Epoch 111/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8937 - mae: 3.8937 \n",
      "Epoch 112/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8951 - mae: 3.8951 \n",
      "Epoch 113/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.4101 - mae: 4.4101 \n",
      "Epoch 114/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.9819 - mae: 3.9819 \n",
      "Epoch 115/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0337 - mae: 4.0337 \n",
      "Epoch 116/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 4.1803 - mae: 4.1803 \n",
      "Epoch 117/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7097 - mae: 3.7097 \n",
      "Epoch 118/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8587 - mae: 3.8587 \n",
      "Epoch 119/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6218 - mae: 3.6218 \n",
      "Epoch 120/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5008 - mae: 3.5008 \n",
      "Epoch 121/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9270 - mae: 3.9270 \n",
      "Epoch 122/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0920 - mae: 4.0920 \n",
      "Epoch 123/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0253 - mae: 4.0253 \n",
      "Epoch 124/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7518 - mae: 3.7518 \n",
      "Epoch 125/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8729 - mae: 3.8729 \n",
      "Epoch 126/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7424 - mae: 3.7424 \n",
      "Epoch 127/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5997 - mae: 3.5997 \n",
      "Epoch 128/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5224 - mae: 3.5224 \n",
      "Epoch 129/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8536 - mae: 3.8536 \n",
      "Epoch 130/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6556 - mae: 3.6556 \n",
      "Epoch 131/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 3.5628 - mae: 3.5628\n",
      "Epoch 132/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6722 - mae: 3.6722 \n",
      "Epoch 133/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8287 - mae: 3.8287 \n",
      "Epoch 134/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0946 - mae: 4.0946 \n",
      "Epoch 135/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9801 - mae: 3.9801 \n",
      "Epoch 136/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8302 - mae: 3.8302 \n",
      "Epoch 137/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6996 - mae: 3.6996 \n",
      "Epoch 138/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6507 - mae: 3.6507 \n",
      "Epoch 139/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8117 - mae: 3.8117 \n",
      "Epoch 140/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6884 - mae: 3.6884 \n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1804 - mae: 4.1804 \n",
      "Epoch 142/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3545 - mae: 4.3545 \n",
      "Epoch 143/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1679 - mae: 4.1679 \n",
      "Epoch 144/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.2277 - mae: 4.2277 \n",
      "Epoch 145/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7168 - mae: 3.7168 \n",
      "Epoch 146/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 3.6189 - mae: 3.6189\n",
      "Epoch 147/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9747 - mae: 3.9747 \n",
      "Epoch 148/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0635 - mae: 4.0635 \n",
      "Epoch 149/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.7234 - mae: 3.7234 \n",
      "Epoch 150/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.5774 - mae: 3.5774 \n",
      "Epoch 151/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6437 - mae: 3.6437 \n",
      "Epoch 152/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5345 - mae: 3.5345 \n",
      "Epoch 153/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.4435 - mae: 3.4435 \n",
      "Epoch 154/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.8344 - mae: 3.8344 \n",
      "Epoch 155/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8952 - mae: 3.8952 \n",
      "Epoch 156/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6235 - mae: 3.6235 \n",
      "Epoch 157/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6156 - mae: 3.6156 \n",
      "Epoch 158/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - loss: 3.7116 - mae: 3.7116\n",
      "Epoch 159/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3365 - mae: 4.3365 \n",
      "Epoch 160/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7069 - mae: 3.7069 \n",
      "Epoch 161/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6846 - mae: 3.6846 \n",
      "Epoch 162/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7168 - mae: 3.7168 \n",
      "Epoch 163/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7762 - mae: 3.7762 \n",
      "Epoch 164/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.9946 - mae: 3.9946 \n",
      "Epoch 165/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6198 - mae: 3.6198 \n",
      "Epoch 166/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6145 - mae: 3.6145 \n",
      "Epoch 167/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5438 - mae: 3.5438 \n",
      "Epoch 168/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7539 - mae: 3.7539 \n",
      "Epoch 169/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.0943 - mae: 4.0943 \n",
      "Epoch 170/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5727 - mae: 3.5727 \n",
      "Epoch 171/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6621 - mae: 3.6621 \n",
      "Epoch 172/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5672 - mae: 3.5672 \n",
      "Epoch 173/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7706 - mae: 3.7706 \n",
      "Epoch 174/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6522 - mae: 3.6522 \n",
      "Epoch 175/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6096 - mae: 3.6096 \n",
      "Epoch 176/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7373 - mae: 3.7373 \n",
      "Epoch 177/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7296 - mae: 3.7296 \n",
      "Epoch 178/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6580 - mae: 3.6580 \n",
      "Epoch 179/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.2680 - mae: 4.2680 \n",
      "Epoch 180/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.3162 - mae: 4.3162 \n",
      "Epoch 181/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8432 - mae: 4.8432 \n",
      "Epoch 182/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.8641 - mae: 3.8641 \n",
      "Epoch 183/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7639 - mae: 3.7639 \n",
      "Epoch 184/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.4615 - mae: 3.4615 \n",
      "Epoch 185/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.5052 - mae: 3.5052 \n",
      "Epoch 186/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.6654 - mae: 3.6654 \n",
      "Epoch 187/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.6578 - mae: 3.6578 \n",
      "Epoch 188/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3275 - mae: 4.3275 \n",
      "Epoch 189/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.4338 - mae: 4.4338 \n",
      "Epoch 190/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7041 - mae: 3.7041 \n",
      "Epoch 191/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7863 - mae: 3.7863 \n",
      "Epoch 192/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7730 - mae: 3.7730 \n",
      "Epoch 193/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.6229 - mae: 4.6229 \n",
      "Epoch 194/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.8026 - mae: 4.8026 \n",
      "Epoch 195/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.3174 - mae: 4.3174 \n",
      "Epoch 196/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.0609 - mae: 4.0609 \n",
      "Epoch 197/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3.7835 - mae: 3.7835 \n",
      "Epoch 198/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.1185 - mae: 4.1185 \n",
      "Epoch 199/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4.5415 - mae: 4.5415 \n",
      "Epoch 200/200\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.1471 - mae: 4.1471 \n"
     ]
    }
   ],
   "source": [
    "#FINAL\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "boston_housing_model_6 = tf.keras.Sequential([\n",
    "     tf.keras.layers.Dense(100,activation = None),\n",
    "     tf.keras.layers.Dense(10,activation = None), \n",
    "     tf.keras.layers.Dense(10,activation = None),\n",
    "     tf.keras.layers.Dense(1,activation = None)\n",
    "])\n",
    "\n",
    "\n",
    "boston_housing_model_6.compile(loss = tf.keras.losses.mae,\n",
    "                               optimizer = tf.keras.optimizers.Adam(learning_rate = 0.1),\n",
    "                               metrics = [\"mae\"])\n",
    "\n",
    "history_6 = boston_housing_model_6.fit(x_train,y_train,epochs = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "a9896a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 3.8286 - mae: 3.8286  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.066843509674072, 4.066843509674072]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_housing_model_6.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "09d0aaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.239702],\n",
       "       [21.802946],\n",
       "       [24.715246],\n",
       "       [30.067665],\n",
       "       [26.554646],\n",
       "       [23.262424],\n",
       "       [33.838318],\n",
       "       [28.205044],\n",
       "       [20.894733],\n",
       "       [22.269432],\n",
       "       [19.79803 ],\n",
       "       [21.614502],\n",
       "       [19.071428],\n",
       "       [34.04806 ],\n",
       "       [18.860994],\n",
       "       [24.488134],\n",
       "       [25.417664],\n",
       "       [23.096596],\n",
       "       [20.369713],\n",
       "       [25.567953],\n",
       "       [13.350868],\n",
       "       [14.630312],\n",
       "       [24.180922],\n",
       "       [18.855133],\n",
       "       [30.220535],\n",
       "       [22.862278],\n",
       "       [31.03271 ],\n",
       "       [34.918083],\n",
       "       [12.769207],\n",
       "       [24.190506],\n",
       "       [24.120684],\n",
       "       [15.996577],\n",
       "       [37.027916],\n",
       "       [24.51271 ],\n",
       "       [19.529224],\n",
       "       [ 9.804834],\n",
       "       [18.803167],\n",
       "       [21.21631 ],\n",
       "       [17.668354],\n",
       "       [35.126747],\n",
       "       [26.905117],\n",
       "       [28.11451 ],\n",
       "       [19.85651 ],\n",
       "       [33.18132 ],\n",
       "       [30.599413],\n",
       "       [25.718391],\n",
       "       [33.046787],\n",
       "       [21.024788],\n",
       "       [24.201881],\n",
       "       [25.296715],\n",
       "       [38.64692 ],\n",
       "       [19.691801],\n",
       "       [13.759262],\n",
       "       [18.169209],\n",
       "       [35.36168 ],\n",
       "       [28.022957],\n",
       "       [19.28272 ],\n",
       "       [37.836716],\n",
       "       [37.882214],\n",
       "       [25.66341 ],\n",
       "       [24.81655 ],\n",
       "       [21.473072],\n",
       "       [17.53228 ],\n",
       "       [23.67443 ],\n",
       "       [26.497452],\n",
       "       [31.936531],\n",
       "       [18.73771 ],\n",
       "       [31.277529],\n",
       "       [ 6.894058],\n",
       "       [14.244692],\n",
       "       [25.616093],\n",
       "       [28.505373],\n",
       "       [22.169374],\n",
       "       [10.780476],\n",
       "       [30.4238  ],\n",
       "       [23.786907],\n",
       "       [23.83384 ],\n",
       "       [25.73894 ],\n",
       "       [33.609528],\n",
       "       [10.567333],\n",
       "       [24.953047],\n",
       "       [36.29477 ],\n",
       "       [21.333527],\n",
       "       [20.279392],\n",
       "       [22.95675 ],\n",
       "       [21.61016 ],\n",
       "       [21.849392],\n",
       "       [24.851036],\n",
       "       [25.89615 ],\n",
       "       [26.517483],\n",
       "       [19.69905 ],\n",
       "       [26.225185],\n",
       "       [28.904621],\n",
       "       [31.756626],\n",
       "       [34.20076 ],\n",
       "       [23.838598],\n",
       "       [35.675446],\n",
       "       [35.11881 ],\n",
       "       [25.314602],\n",
       "       [35.933502],\n",
       "       [31.670315],\n",
       "       [22.975107]], dtype=float32)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_housing_model_6_pred = boston_housing_model_6.predict(x_test)\n",
    "boston_housing_model_6_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "2845068f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_housing_model_6_pred.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "d552e5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_housing_model_6_pred_squeeze = tf.squeeze(tf.constant(boston_housing_model_6_pred))\n",
    "type(boston_housing_model_6_pred_squeeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "f82f431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_housing_model_6_pred_squeeze = boston_housing_model_6_pred_squeeze.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "5c95a869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2</td>\n",
       "      <td>9.239702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.8</td>\n",
       "      <td>21.802946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>24.715246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>30.067665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.2</td>\n",
       "      <td>26.554646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>21.9</td>\n",
       "      <td>35.118809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>24.1</td>\n",
       "      <td>25.314602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>50.0</td>\n",
       "      <td>35.933502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>26.7</td>\n",
       "      <td>31.670315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>25.0</td>\n",
       "      <td>22.975107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test     y_pred\n",
       "0       7.2   9.239702\n",
       "1      18.8  21.802946\n",
       "2      19.0  24.715246\n",
       "3      27.0  30.067665\n",
       "4      22.2  26.554646\n",
       "..      ...        ...\n",
       "97     21.9  35.118809\n",
       "98     24.1  25.314602\n",
       "99     50.0  35.933502\n",
       "100    26.7  31.670315\n",
       "101    25.0  22.975107\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_y_test_pred = pd.DataFrame({'y_test' : y_test, 'y_pred' : boston_housing_model_6_pred_squeeze})\n",
    "d_y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "365b1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred = boston_housing_model_6_pred_squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "8220b9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0668435, 28.477053)"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mae (y_true,y_pred):\n",
    "    return tf.keras.metrics.mae(y_true = y_test , y_pred = boston_housing_model_6_pred_squeeze).numpy()\n",
    "\n",
    "def mse (y_true,y_pred):\n",
    "    return tf.keras.metrics.mse(y_true = y_test, y_pred = boston_housing_model_6_pred_squeeze).numpy()\n",
    "\n",
    "mae(y_true,y_pred) , mse(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "cf0251cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history_6.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d84fcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112798d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
